\documentclass[../Thesis.tex]{subfiles}
\graphicspath{{\subfix{../figures/}}}
\begin{document}

\chapter{Conclusion}\label{chap:conclusion}
\begin{itemize}
    \item Long chains can be a problem when the links have varying strength. We observe that the chain might break at the weak points and more strongly connected parts bleed into neighboring nodes resulting in \textit{dense} subgraphs.
    \item Long chains using MI with highr correlation if symmetric seem to be connected $i - i+1$ and $i - i+2$. If very large MI might want to treat differently.
    \item Works well, trough experimentation, on linear networks. If $X_j = f(\sum X_i)$ for in-neighbors it is not necessarily well, however as MI is independent of marginals, we expect better performance on these systems than if one had used correlation. In particular, if it is a chain, transforming each variable gives exactly the same result.
    \item Although \cite{An_effective_approach_for_causal_variables_analysis_in_diesel_engine_production_by_using_mutual_information_and_network_deconvolution} use normalized mutual information, we have not done this. However, it will be easy to extend the code we have produced to use this instead as we already compute the entropies. However, it is no longer invariant to marginal transformations and ideally, the entropy is 0 for marginals as are transformed to be uniform. However if instead we comput ethe entropy for the marginals without transforming, we can use the constructed framework in extension to calculate the mutual information and from that the normalized mutual information
\end{itemize}

\end{document}


